{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0ae03d948584253fec240bc08d589a6fc5490ee03a1d28d126cf31e5ae02e89c9",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 2\n",
    "\n",
    "Assigment is in the intersection of Named Entity Recognition and Dependency Parsing.\n",
    "\n",
    "1. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "    - report token-level performance (per class and total)\n",
    "        - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "    - report CoNLL chunk-level performance (per class and total);\n",
    "        - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  \n",
    "\n",
    "2. Grouping of Entities.\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together). \n",
    "\n",
    "3. One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Preprocessing\n",
    "Parse corpus with spaCy and align results to CoNLL tokenization and sentence segmentation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import conll\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATASET_PATH = 'data/test.txt'\n",
    "\n",
    "# Read dataset\n",
    "corpus = conll.read_corpus_conll(DATASET_PATH, fs=' ')\n",
    "corpus = list(filter(lambda sent: sent[0][0] != '-DOCSTART-', corpus)) # Remove -DOCSTART- sentences\n",
    "words = [word[0] for sent in corpus for word in sent]\n",
    "\n",
    "# Parse with spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = Doc(nlp.vocab, words)\n",
    "\n",
    "# Custom sentence split, to allineate the spaCy results to CoNLL\n",
    "i = 0\n",
    "for sent in corpus:\n",
    "    for j, word in enumerate(sent):\n",
    "        doc[i].is_sent_start = (j == 0) # Set to true only when first word in sentence\n",
    "        i += 1\n",
    "\n",
    "# NER with spaCy\n",
    "for name, proc in nlp.pipeline:\n",
    "    doc = proc(doc)"
   ]
  },
  {
   "source": [
    "## 1. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "- report token-level performance (per class and total)\n",
    "    - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "- report CoNLL chunk-level performance (per class and total);\n",
    "    - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token-level perfomance\n               precision    recall  f1-score   support\n\n       B-LOC      0.780     0.692     0.733      1668\n      B-MISC      0.107     0.553     0.179       702\n       B-ORG      0.513     0.289     0.370      1661\n       B-PER      0.779     0.607     0.683      1617\n       I-LOC      0.566     0.630     0.597       257\n      I-MISC      0.055     0.389     0.096       216\n       I-ORG      0.459     0.499     0.478       835\n       I-PER      0.829     0.735     0.779      1156\n           O      0.940     0.868     0.902     38323\n\n    accuracy                          0.813     46435\n   macro avg      0.559     0.585     0.535     46435\nweighted avg      0.883     0.813     0.843     46435\n\n\n\nChunk-level perfomance\n            p      r      f     s\nLOC    0.769  0.682  0.723  1668\nMISC   0.105  0.541  0.175   702\nORG    0.455  0.256  0.328  1661\nPER    0.757  0.590  0.663  1617\ntotal  0.397  0.513  0.447  5648\n"
     ]
    }
   ],
   "source": [
    "# Convert spacy tags to conll\n",
    "def to_conll(iob, ent_type):\n",
    "    conll_type = {\n",
    "        'PERSON': 'PER',\n",
    "        'GPE': 'LOC',\n",
    "        'FAC': 'LOC',\n",
    "        'LOC': 'LOC',\n",
    "        'ORG': 'ORG',\n",
    "        '': '',\n",
    "    }.get(ent_type)\n",
    "    if conll_type is None: \n",
    "        conll_type = 'MISC'\n",
    "    return f'{iob}-{conll_type}'.strip('-')\n",
    "\n",
    "def evaluate(doc):\n",
    "    # Results pre-processing\n",
    "    refs = [[(word[0], word[3]) for word in sent] for sent in corpus]\n",
    "    hyps = [[(word.text, to_conll(word.ent_iob_, word.ent_type_)) for word in sent] for sent in doc.sents]\n",
    "\n",
    "    # Token-level performance\n",
    "    token_lvl = classification_report([w[1] for s in refs for w in s], [w[1] for s in hyps for w in s], digits=3)\n",
    "\n",
    "    # Chunk-level performance\n",
    "    chunk_lvl = conll.evaluate(refs, hyps)\n",
    "    chunk_lvl = pd.DataFrame.from_dict(chunk_lvl, orient='index').sort_index().round(3).to_string()\n",
    "\n",
    "    return token_lvl, chunk_lvl\n",
    "\n",
    "# Compute performances\n",
    "token_lvl, chunk_lvl = evaluate(doc)\n",
    "print('Token-level perfomance\\n', token_lvl)\n",
    "print('\\n')\n",
    "print('Chunk-level perfomance\\n', chunk_lvl)"
   ]
  },
  {
   "source": [
    "## 2. Grouping of Entities\n",
    "\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11157/11157 [04:08<00:00, 44.88it/s]\n",
      "\n",
      "Groups frequencies\n",
      "                              freq\n",
      "CARDINAL                     1500\n",
      "GPE                          1246\n",
      "PERSON                       1021\n",
      "DATE                          860\n",
      "ORG                           831\n",
      "NORP                          292\n",
      "MONEY                         146\n",
      "ORDINAL                       119\n",
      "CARDINAL_PERSON                92\n",
      "TIME                           80\n",
      "PERCENT                        70\n",
      "EVENT                          57\n",
      "QUANTITY                       51\n",
      "LOC                            49\n",
      "NORP_PERSON                    41\n",
      "GPE_PERSON                     32\n",
      "ORG_PERSON                     24\n",
      "PRODUCT                        23\n",
      "FAC                            23\n",
      "CARDINAL_ORG                   19\n",
      "CARDINAL_GPE                   18\n",
      "CARDINAL_NORP                  18\n",
      "GPE_GPE                        17\n",
      "LAW                            13\n",
      "WORK_OF_ART                    13\n",
      "GPE_ORG                        12\n",
      "ORG_ORG                         9\n",
      "DATE_TIME                       7\n",
      "GPE_ORDINAL                     7\n",
      "PERSON_PERSON                   7\n",
      "DATE_EVENT                      7\n",
      "GPE_PRODUCT                     7\n",
      "NORP_ORG                        7\n",
      "LANGUAGE                        6\n",
      "DATE_PERSON                     6\n",
      "GPE_CARDINAL                    6\n",
      "GPE_DATE                        5\n",
      "CARDINAL_CARDINAL               5\n",
      "NORP_ORDINAL                    5\n",
      "PERSON_GPE                      5\n",
      "ORG_GPE                         4\n",
      "CARDINAL_GPE_GPE                3\n",
      "PERSON_CARDINAL                 3\n",
      "LANGUAGE_ORDINAL                3\n",
      "DATE_ORG                        3\n",
      "NORP_NORP                       2\n",
      "ORDINAL_GPE                     2\n",
      "ORG_NORP                        2\n",
      "ORDINAL_PERSON                  2\n",
      "ORG_CARDINAL                    2\n",
      "ORDINAL_EVENT                   2\n",
      "DATE_NORP                       2\n",
      "CARDINAL_CARDINAL_ORG           2\n",
      "GPE_FAC                         2\n",
      "DATE_NORP_PERSON                2\n",
      "GPE_LOC                         2\n",
      "ORG_DATE                        2\n",
      "PERSON_ORG                      2\n",
      "PERSON_PRODUCT_ORDINAL          1\n",
      "ORG_NORP_PERSON                 1\n",
      "CARDINAL_CARDINAL_NORP          1\n",
      "ORG_MONEY                       1\n",
      "PERSON_MONEY                    1\n",
      "PERSON_PERSON_PERSON            1\n",
      "QUANTITY_QUANTITY               1\n",
      "PERSON_FAC                      1\n",
      "CARDINAL_CARDINAL_PERSON        1\n",
      "EVENT_CARDINAL                  1\n",
      "ORG_QUANTITY                    1\n",
      "PERSON_NORP_PERSON              1\n",
      "DATE_CARDINAL                   1\n",
      "ORG_WORK_OF_ART                 1\n",
      "CARDINAL_DATE                   1\n",
      "PERSON_ORDINAL                  1\n",
      "GPE_CARDINAL_ORG                1\n",
      "CARDINAL_EVENT                  1\n",
      "ORDINAL_TIME                    1\n",
      "GPE_DATE_ORG                    1\n",
      "GPE_ORDINAL_PERSON              1\n",
      "CARDINAL_GPE_TIME               1\n",
      "GPE_PERSON_CARDINAL             1\n",
      "GPE_PERSON_PERSON               1\n",
      "FAC_GPE                         1\n",
      "GPE_PRODUCT_CARDINAL            1\n",
      "DATE_LANGUAGE_ORDINAL           1\n",
      "LOC_DATE                        1\n",
      "LOC_ORDINAL                     1\n",
      "MONEY_CARDINAL_CARDINAL_ORG     1\n",
      "MONEY_MONEY                     1\n",
      "MONEY_PRODUCT                   1\n",
      "DATE_GPE                        1\n",
      "NORP_CARDINAL_CARDINAL          1\n",
      "NORP_DATE                       1\n",
      "NORP_LOC                        1\n",
      "DATE_WORK_OF_ART                1\n",
      "DATE_FAC                        1\n",
      "NORP_PERSON_DATE                1\n",
      "CARDINAL_FAC                    1\n",
      "ORDINAL_NORP                    1\n",
      "ORDINAL_ORG                     1\n",
      "CARDINAL_PERCENT                1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group entities based on noun_chunks method\n",
    "def group_ents(doc):\n",
    "    result = []\n",
    "    i = 0\n",
    "    doc_ents = list(doc.ents)\n",
    "    for chunk in tqdm(list(doc.noun_chunks)):\n",
    "        if len(chunk.ents) > 0:\n",
    "            result.append([]) # Add new chunk in result\n",
    "            for chunk_ent in chunk.ents:\n",
    "                # Misaligned noun_chunks and ents found, create a new chunk\n",
    "                if chunk_ent.text != doc_ents[i].text and len(result[-1]) > 0:\n",
    "                    result.append([])\n",
    "                while i < len(doc_ents) and chunk_ent.text != doc_ents[i].text: # Search for an alignment\n",
    "                    result[-1].append(doc_ents[i].label_) # Add missing ents as standalone chunks\n",
    "                    i+=1\n",
    "                    result.append([])\n",
    "                result[-1].append(doc_ents[i].label_)\n",
    "                i+=1\n",
    "    return result\n",
    "\n",
    "# Compute frequency for each group\n",
    "def evaluate_groups(groups):\n",
    "    result = {}\n",
    "    for group in groups:\n",
    "        key = \"_\".join(group)\n",
    "        if key not in result:\n",
    "            result[key] = {'freq': 0}\n",
    "        result[key]['freq'] += 1\n",
    "    return result\n",
    "\n",
    "# Compute metrics\n",
    "ents_groups = group_ents(doc)\n",
    "groups_freq = evaluate_groups(ents_groups)\n",
    "groups_freq = pd.DataFrame.from_dict(groups_freq, orient='index').sort_values(by='freq', ascending=False).to_string()\n",
    "print('\\n')\n",
    "print('Groups frequencies\\n', groups_freq)"
   ]
  },
  {
   "source": [
    "## 3. Fix segmentation errors\n",
    "One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token-level perfomance\n               precision    recall  f1-score   support\n\n       B-LOC      0.765     0.679     0.719      1668\n      B-MISC      0.107     0.551     0.179       702\n       B-ORG      0.503     0.284     0.363      1661\n       B-PER      0.675     0.526     0.592      1617\n       I-LOC      0.373     0.634     0.470       257\n      I-MISC      0.048     0.394     0.086       216\n       I-ORG      0.398     0.511     0.448       835\n       I-PER      0.670     0.747     0.707      1156\n           O      0.941     0.849     0.893     38323\n\n    accuracy                          0.795     46435\n   macro avg      0.498     0.575     0.495     46435\nweighted avg      0.874     0.795     0.828     46435\n\n\n\nChunk-level perfomance\n            p      r      f     s\nLOC    0.707  0.627  0.665  1668\nMISC   0.095  0.493  0.160   702\nORG    0.371  0.209  0.267  1661\nPER    0.647  0.504  0.567  1617\ntotal  0.350  0.452  0.394  5648\n"
     ]
    }
   ],
   "source": [
    "new_doc = doc.copy()\n",
    "new_ents = []\n",
    "x = set()\n",
    "for ent in new_doc.ents:\n",
    "    new_ents.append(ent)\n",
    "    ent_tokens = list(ent)\n",
    "    for token in ent_tokens:\n",
    "        # children + parent as candidates to be added to the NE\n",
    "        candidates = [(c, c.dep_) for c in token.children] + [(token.head, token.dep_)]\n",
    "        # Check for each candidate if it is a valid, i.e. if it has not already been added to another NE\n",
    "        for candidate, dep in candidates:\n",
    "            if(dep == 'compound' and candidate.ent_type_ == '' and \n",
    "            (candidate.i == new_ents[-1].start-1 or candidate.i + 1 == new_ents[-1].end + 1)):\n",
    "                # Mark the newly added token with the ne entity label, to avoid readding it to another NE\n",
    "                candidate.ent_type_ = new_ents[-1].label_ \n",
    "                # Create a new Span for the new entity\n",
    "                # N.B.: spaCy will add the correct ent_type_ and ent_iob_ attributes to the new generated entity span\n",
    "                new_start, new_end = min(new_ents[-1].start, candidate.i), max(new_ents[-1].end, candidate.i + 1) \n",
    "                new_ents[-1] = Span(new_doc, new_start, new_end, new_ents[-1].label_)\n",
    "                # Add the new candidate token to the list of tokens to be processed\n",
    "                ent_tokens.append(candidate)\n",
    "new_doc.set_ents(new_ents)\n",
    "\n",
    "# Compute performances\n",
    "new_token_lvl, new_chunk_lvl = evaluate(new_doc)\n",
    "print('Token-level perfomance\\n', new_token_lvl)\n",
    "print('\\n')\n",
    "print('Chunk-level perfomance\\n', new_chunk_lvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}