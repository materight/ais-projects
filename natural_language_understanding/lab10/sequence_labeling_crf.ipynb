{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence Labeling with Conditional Random Fields (CRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Evgeny A. Stepanov\n",
    "- stepanov.evgeny.a@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Recommended Reading*\n",
    "- Lecture Slides\n",
    "- Lafferty et al. (2001) [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.803&rep=rep1&type=pdf) (__original paper__)\n",
    "- Sutton & McCallum's [An Introduction to Conditional Random Fields](https://homepages.inf.ed.ac.uk/csutton/publications/crftutv2.pdf)\n",
    "- Edwin Chen's [Introduction to Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n",
    "- Michael Collin's [Log-Linear Models, MEMMs, and CRFs](http://www.cs.columbia.edu/~mcollins/crf.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Requirements__\n",
    "\n",
    "- [NL2SparQL4NLU](https://github.com/esrel/NL2SparQL4NLU) dataset\n",
    "- [CRFsuite](http://www.chokkan.org/software/crfsuite/)\n",
    "    - [python-crfsuite](https://python-crfsuite.readthedocs.io) python binding to `CRFsuite`.\n",
    "    - [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io) `python-crfsuite` wrapper providing API similar to `scikit-learn`\n",
    "- [spaCy](https://spacy.io/)\n",
    "- `conll.py` (in `src` folder)\n",
    "\n",
    "__Note:__ you need to install both `python_crfsuite` and `sklearn_crfsuite` to use `sklearn_crfsuite`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Random Fields\n",
    "\n",
    "[CRFs](https://en.wikipedia.org/wiki/Conditional_random_field) are a type of __discriminative undirected probabilistic graphical model__. \n",
    "It is a generalization of __any__ undirected graph structure.\n",
    "In Natural Language Processing, the structure is a *sequence* of words, and conditioning is on *previous transition*. This is known as __Linear Chain CRFs__.\n",
    "\n",
    "For general graphs, the problem of exact inference in CRFs is intractable. For __Linear Chain CRFs__, however, there is an exact solution, and the used algorithm is \"analogous to the forward-backward and Viterbi algorithm for the case of Hidden Markov Models\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why CRF?\n",
    "- Hidden Markov Models (HMM) have two issues when working with textual data:\n",
    "    - Unrealistic independence assumptions: Natural Language Requires richer representation than just words (i.e. more features), which are __not independent__ (e.g. word and its suffix)\n",
    "    -  HMM maximizes the likelihood of the observation sequence; however, in NLP the task is to predict the state sequence given the observation sequence, i.e. in generative approach we use __joint model__ to solve a __conditional problem__ (since we have observations, not state sequences.\n",
    "    \n",
    "- Maximum Entropy Markov Models (MEMM, McCallum et al. 2000) address these problems. However, they have a __label bias problem__ -- outgoing transitions from a state compete only against each other (not all the transitions in a model). In other words, \"transition scores are the conditional probabilities of possible next states given the current state and the observation sequence\". Consequently, MEMM favors states with fewer outgoing transitions (to the point of ignoring the observations, if there is only one outgoing transition). \n",
    "\n",
    "- Conditional Random Fields solve the __label bias problem__.\n",
    "\n",
    "> A MEMM uses per-state exponential models for the conditional probabilities of next states given the current state, while a CRF has a single exponential model for the joint probability of a label sequence given the observation sequence. Since normalization is done globally rather than for each state individually, the weights of different features at different states can be traded off against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### State-of-the-Art in the Age of Deep Neural Networks\n",
    "\n",
    "Recently, it is considered to be *no-brainer* to combine CRFs with LSTMs (stack CRF on top of LSTM layer, e.g. Gobbi et al.) to improve accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python CRF Tutorials\n",
    "\n",
    "Authors of the python packages provide tutorials in the form of notebooks already!\n",
    "\n",
    "__Follow the tutorials to learn the tools.__\n",
    "\n",
    "- [sklearn-crfsuite notebook](https://github.com/TeamHG-Memex/sklearn-crfsuite/blob/master/docs/CoNLL2002.ipynb)\n",
    "- [python-crfsuite notebook](https://github.com/scrapinghub/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`bias` is explained [here](https://github.com/scrapinghub/python-crfsuite/issues/73)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Language Understanding (Tagging) with CRFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baseline\n",
    "\n",
    "Let's prepare a CRF baseline for our dataset that:\n",
    "- considers only word itself and the previous tag (similar to HMM).\n",
    "\n",
    "We will make use of functions defined on previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus_conll(corpus_file, fs=\"\\t\"):\n",
    "    \"\"\"\n",
    "    read corpus in CoNLL format\n",
    "    :param corpus_file: corpus in conll format\n",
    "    :param fs: field separator\n",
    "    :return: corpus\n",
    "    \"\"\"\n",
    "    featn = None  # number of features for consistency check\n",
    "    sents = []  # list to hold words list sequences\n",
    "    words = []  # list to hold feature tuples\n",
    "\n",
    "    for line in open(corpus_file):\n",
    "        line = line.strip()\n",
    "        if len(line.strip()) > 0:\n",
    "            feats = tuple(line.strip().split(fs))\n",
    "            if not featn:\n",
    "                featn = len(feats)\n",
    "            elif featn != len(feats) and len(feats) != 0:\n",
    "                raise ValueError(\"Unexpected number of columns {} ({})\".format(len(feats), featn))\n",
    "            words.append(feats)\n",
    "        else:\n",
    "            if len(words) > 0:\n",
    "                sents.append(words)\n",
    "                words = []\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "trn_data_file = 'NL2SparQL4NLU/dataset/NL2SparQL4NLU.train.conll.txt' \n",
    "tst_data_file = 'NL2SparQL4NLU/dataset/NL2SparQL4NLU.test.conll.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('who', 'O'), ('plays', 'O'), ('luke', 'B-character.name'), ('on', 'O'), ('star', 'B-movie.name'), ('wars', 'I-movie.name'), ('new', 'I-movie.name'), ('hope', 'I-movie.name')]\n"
     ]
    }
   ],
   "source": [
    "trn = read_corpus_conll(trn_data_file)\n",
    "tst = read_corpus_conll(tst_data_file)\n",
    "print(trn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's copy & re-define feature extraction functions from the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    return {'bias': 1.0, 'word.lower()': word.lower()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's inspect our baseline features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0, 'word.lower()': 'who'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(trn[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 ms, sys: 3.06 ms, total: 21.5 ms\n",
      "Wall time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_feats = [sent2features(s) for s in trn]\n",
    "trn_label = [sent2labels(s) for s in trn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 17.2 ms, total: 6.42 s\n",
      "Wall time: 6.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn_crfsuite.estimator.CRF at 0x11993b550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(trn_feats, trn_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tst_feats = [sent2features(s) for s in tst]\n",
    "pred = crf.predict(tst_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Evaluation\n",
    "We are going to use our `conll` evaluation script. (Notice that tools report token level metrics.)\n",
    "\n",
    "For that we will need to modify our prediction output a bit, to make it a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-movie.name']\n"
     ]
    }
   ],
   "source": [
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hyp = [[(tst_feats[i][j], t) for j, t in enumerate(tokens)] for i, tokens in enumerate(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.444</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.613</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.787</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.709</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.667</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.638</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.118</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.581</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.755</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.967</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.839</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.579</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.415</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.807</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.751</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "movie.location        1.000  0.286  0.444     7\n",
       "country.name          0.560  0.677  0.613    62\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.release_region  1.000  0.000  0.000     4\n",
       "movie.genre           0.960  0.667  0.787    36\n",
       "movie.subject         0.800  0.636  0.709    44\n",
       "producer.name         0.746  0.603  0.667    73\n",
       "movie.language        0.787  0.536  0.638    69\n",
       "character.name        0.500  0.067  0.118    15\n",
       "director.name         0.608  0.556  0.581    81\n",
       "movie.release_date    0.833  0.690  0.755    29\n",
       "actor.type            1.000  1.000  1.000     2\n",
       "rating.name           0.983  0.951  0.967    61\n",
       "award.ceremony        0.500  0.429  0.462     7\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "movie.name            0.857  0.822  0.839   473\n",
       "person.name           0.579  0.324  0.415    34\n",
       "movie.star_rating     1.000  0.000  0.000     1\n",
       "movie.gross_revenue   0.400  0.400  0.400     5\n",
       "actor.name            0.779  0.838  0.807    80\n",
       "actor.nationality     1.000  0.000  0.000     1\n",
       "total                 0.796  0.710  0.751  1091"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to import conll\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "from conll import evaluate\n",
    "# for nice tables\n",
    "import pandas as pd\n",
    "\n",
    "results = evaluate(tst, hyp)\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One of the strengths of CRFs lies in its ability to make use of rich feature representation. The process of extracting features from raw data is know as [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering).\n",
    "\n",
    "Common features used in sequence labeling with CRFs are:\n",
    "- part-of-speech tags\n",
    "- lemmas\n",
    "- token character prefixes and suffixes (e.g. first and last 1, 2, 3 characters of a word; `word[-3:]` in tutorial is suffix of length 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### SpaCy\n",
    "\n",
    "[spaCy](https://spacy.io/) provides a convenient way to augment our feature set with common features using in Natural Language Processing. To make use of spaCy, please install it and download the model as:\n",
    "\n",
    "```\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "The list of provided token-level features is available [here](https://spacy.io/api/token#attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's modify `sent2features` function to make use of spaCy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)  # to use white space tokenization (generally a bad idea for unknown data)\n",
    "\n",
    "def sent2spacy_features(sent):\n",
    "    spacy_sent = nlp(\" \".join(sent2tokens(sent)))\n",
    "    feats = []\n",
    "    for token in spacy_sent:\n",
    "        token_feats = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': token.lower_,\n",
    "            'pos': token.pos_,\n",
    "            'lemma': token.lemma_\n",
    "        }\n",
    "        feats.append(token_feats)\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "trn_feats = [sent2spacy_features(s) for s in trn]\n",
    "trn_label = [sent2labels(s) for s in trn]\n",
    "tst_feats = [sent2spacy_features(s) for s in tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bias': 1.0, 'word.lower()': 'who', 'pos': 'PRON', 'lemma': 'who'}, {'bias': 1.0, 'word.lower()': 'plays', 'pos': 'VERB', 'lemma': 'play'}, {'bias': 1.0, 'word.lower()': 'luke', 'pos': 'PROPN', 'lemma': 'luke'}, {'bias': 1.0, 'word.lower()': 'on', 'pos': 'ADP', 'lemma': 'on'}, {'bias': 1.0, 'word.lower()': 'star', 'pos': 'PROPN', 'lemma': 'star'}, {'bias': 1.0, 'word.lower()': 'wars', 'pos': 'NOUN', 'lemma': 'war'}, {'bias': 1.0, 'word.lower()': 'new', 'pos': 'PROPN', 'lemma': 'new'}, {'bias': 1.0, 'word.lower()': 'hope', 'pos': 'PROPN', 'lemma': 'hope'}]\n"
     ]
    }
   ],
   "source": [
    "print(trn_feats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn_crfsuite.estimator.CRF at 0x11d7ae790>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(trn_feats, trn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred = crf.predict(tst_feats)\n",
    "\n",
    "hyp = [[(tst_feats[i][j], t) for j, t in enumerate(tokens)] for i, tokens in enumerate(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.444</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.595</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.667</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.848</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.741</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.783</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.707</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.655</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.211</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.586</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.543</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.750</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.983</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.859</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.514</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.444</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.763</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "movie.location        1.000  0.286  0.444     7\n",
       "country.name          0.595  0.758  0.667    62\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.release_region  0.000  0.000  0.000     4\n",
       "movie.genre           0.933  0.778  0.848    36\n",
       "movie.subject         0.811  0.682  0.741    44\n",
       "producer.name         0.783  0.644  0.707    73\n",
       "movie.language        0.809  0.551  0.655    69\n",
       "character.name        0.500  0.133  0.211    15\n",
       "director.name         0.586  0.506  0.543    81\n",
       "movie.release_date    0.778  0.724  0.750    29\n",
       "actor.type            1.000  1.000  1.000     2\n",
       "rating.name           1.000  0.967  0.983    61\n",
       "award.ceremony        0.500  0.429  0.462     7\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "movie.name            0.880  0.839  0.859   473\n",
       "person.name           0.500  0.529  0.514    34\n",
       "movie.star_rating     1.000  0.000  0.000     1\n",
       "movie.gross_revenue   0.500  0.400  0.444     5\n",
       "actor.name            0.710  0.825  0.763    80\n",
       "actor.nationality     1.000  1.000  1.000     1\n",
       "total                 0.797  0.737  0.766  1091"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate(tst, hyp)\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- add suffix features to the model and report performances\n",
    "- try the feature template from the tutorial on NL2SparQL4NLU\n",
    "- increase the feature window (number of previous and next token) to:\n",
    "    - `[-1, +1]`\n",
    "    - `[-2, +2]`\n",
    "- learn & experiment with [model parameters](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
