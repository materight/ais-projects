{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence Labeling with Deep Neural Networks\n",
    "- Evgeny A. Stepanov\n",
    "- stepanov.evgeny.a@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Recommended Reading*:\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Fran√ßois Chollet (2017) Deep Learning with Python\n",
    "\n",
    "*Notebook Covers Material of*:\n",
    "- [SLP](https://web.stanford.edu/~jurafsky/slp3/9.pdf) Chapter 9: Deep Learning Architectures for Sequence Processing\n",
    "\n",
    "__Requirements__\n",
    "\n",
    "- [keras](https://keras.io/)\n",
    "- [tensorflow](https://www.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To train an RNN with Keras the following steps are required:\n",
    "\n",
    "- transformation of the input into tensors\n",
    "    - preparing the data\n",
    "- building a model using layers\n",
    "- compiling the model, specifying\n",
    "    - loss function\n",
    "    - optimizer for gradient descent\n",
    "    - evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparing Corpus for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the Corpus in CoNLL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# to import conll\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "from conll import evaluate, read_corpus_conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trn = read_corpus_conll('../data/NL2SPARQL4NLU/train.txt')\n",
    "tst = read_corpus_conll('../data/NL2SPARQL4NLU/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('who', 'O'), ('plays', 'O'), ('luke', 'B-character.name'), ('on', 'O'), ('star', 'B-movie.name'), ('wars', 'I-movie.name'), ('new', 'I-movie.name'), ('hope', 'I-movie.name')]\n"
     ]
    }
   ],
   "source": [
    "print(trn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Extraction\n",
    "Keras, like most algorithms, work with number vectors (i.e. require vectorization of data).\n",
    "We need to:\n",
    "- get vocabulary of words\n",
    "- get vocabulary of tags\n",
    "- create mappings for:\n",
    "    - word to index\n",
    "    - index to word\n",
    "    - tag to index\n",
    "    - index to tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define a helper function to get vocabulary from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# function to get vocabulary\n",
    "# idx specifies the index of the colunm to get (0: words, 1: tags)\n",
    "def get_vocab(data, idx=None):\n",
    "    idx = 0 if idx is None else idx\n",
    "    vocab = set()\n",
    "    for sent in data:\n",
    "        for tok in sent:\n",
    "            vocab.add(tok[idx])\n",
    "    return sorted(list(vocab))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "1728\n"
     ]
    }
   ],
   "source": [
    "words = get_vocab(trn)\n",
    "labels = get_vocab(trn, idx=-1)\n",
    "\n",
    "print(len(labels))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Creating Index Mappings\n",
    "\n",
    "`keras` vocabulary by default has 2 entries with indices `0` and `1` reserved for PADDING token and UNKNOWN token (i.e. OOV). We need those for words. For tags, our padding is `O` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# initial will take a dict mapping for keras default entries\n",
    "def create_idx(vocab, initial=None):\n",
    "    idx = {} if initial is None else initial\n",
    "    inc = len(idx)\n",
    "    tmp = {w: i + inc for i, w in enumerate(vocab)}\n",
    "    idx.update(tmp)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# word index\n",
    "word2idx = create_idx(words, initial={\"<PAD>\":0, \"<UNK>\":1})\n",
    "print(word2idx[\"<UNK>\"])\n",
    "print(word2idx[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-actor.name': 0, 'B-actor.nationality': 1, 'B-actor.type': 2, 'B-award.category': 3, 'B-award.ceremony': 4, 'B-character.name': 5, 'B-country.name': 6, 'B-director.name': 7, 'B-director.nationality': 8, 'B-movie.description': 9, 'B-movie.genre': 10, 'B-movie.gross_revenue': 11, 'B-movie.language': 12, 'B-movie.location': 13, 'B-movie.name': 14, 'B-movie.release_date': 15, 'B-movie.release_region': 16, 'B-movie.star_rating': 17, 'B-movie.subject': 18, 'B-person.name': 19, 'B-person.nationality': 20, 'B-producer.name': 21, 'B-rating.name': 22, 'I-actor.name': 23, 'I-actor.nationality': 24, 'I-award.ceremony': 25, 'I-character.name': 26, 'I-country.name': 27, 'I-director.name': 28, 'I-movie.genre': 29, 'I-movie.gross_revenue': 30, 'I-movie.language': 31, 'I-movie.location': 32, 'I-movie.name': 33, 'I-movie.release_date': 34, 'I-movie.release_region': 35, 'I-movie.subject': 36, 'I-person.name': 37, 'I-producer.name': 38, 'I-rating.name': 39, 'O': 40}\n"
     ]
    }
   ],
   "source": [
    "# label index\n",
    "label2idx = create_idx(labels)\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n"
     ]
    }
   ],
   "source": [
    "# index to label\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "print(idx2label[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD>\n",
      "<UNK>\n"
     ]
    }
   ],
   "source": [
    "# index to word\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "print(idx2word[0])\n",
    "print(idx2word[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vectorization of Data\n",
    "- `keras` accepts integer vectorization, where words are replaced by their indices.\n",
    "- for batch processing the input sequences must be of the same length; thus we need to identify max sequence length we want to handle (the longest sequence in training)\n",
    "- all the data needs to be padded to this max length (or truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual: ['who', 'plays', 'luke', 'on', 'star', 'wars', 'new', 'hope']\n",
      "Encoded: [1678, 1149, 911, 1066, 1457, 1650, 1026, 734]\n"
     ]
    }
   ],
   "source": [
    "# vectorization of data\n",
    "x_trn_int = [[word2idx[w] for w, t in s] for s in trn]\n",
    "print(\"Textual: {}\".format(list(map(lambda x: x[0], trn[0]))))\n",
    "print(\"Encoded: {}\".format(x_trn_int[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# let's get max length, or 25, if it is less\n",
    "# check test set max size for simplicity, not to deal with evaluation of truncated data\n",
    "max_len = max(max(map(len, x_trn_int)), 25)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Padding & Truncating\n",
    "(from documentation)\n",
    "- `pad_sequences` function transforms a list (of length `num_samples`) of sequences (lists of integers) into a 2D Numpy array of shape (`num_samples`, `num_timesteps`). `num_timesteps` is either the `maxlen` argument if provided, or the length of the longest sequence in the list.\n",
    "\n",
    "- Sequences that are shorter than `num_timesteps` are padded with `value` until they are `num_timesteps` long.\n",
    "\n",
    "- Sequences longer than `num_timesteps` are truncated so that they fit the desired length.\n",
    "\n",
    "- The position where padding or truncation happens is determined by the arguments `padding` and `truncating`, respectively. Pre-padding or removing values from the beginning of the sequence is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1678 1149  911 1066 1457 1650 1026  734    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# let's pad the sentences to max length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_trn_pad = pad_sequences(maxlen=max_len, sequences=x_trn_int, padding=\"post\", value=word2idx['<PAD>'])\n",
    "\n",
    "# value is 0, since it is the <PAD>'s index\n",
    "print(x_trn_pad[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vectorization of Labels\n",
    "\n",
    "- let's vectorize labels the same way as words & pad them\n",
    "- additionally, we need to do one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textual: ['O', 'O', 'B-character.name', 'O', 'B-movie.name', 'I-movie.name', 'I-movie.name', 'I-movie.name']\n",
      "Encoded & Padded: [40 40  5 40 14 33 33 33 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40]\n"
     ]
    }
   ],
   "source": [
    "y_trn_int = [[label2idx[t] for w, t in s] for s in trn]\n",
    "y_trn_pad = pad_sequences(maxlen=max_len, sequences=y_trn_int, padding=\"post\", value=label2idx['O'])\n",
    "\n",
    "# 40 is the id of 'O'\n",
    "print(\"Textual: {}\".format(list(map(lambda x: x[1], trn[0]))))\n",
    "print(\"Encoded & Padded: {}\".format(y_trn_pad[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 41)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_trn_ohv = [to_categorical(i, num_classes=len(labels)) for i in y_trn_pad]\n",
    "\n",
    "print(y_trn_ohv[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3338, 25)\n",
      "(3338, 25, 41)\n"
     ]
    }
   ],
   "source": [
    "# converting data to numpy array\n",
    "import numpy as np\n",
    "\n",
    "x_trn = np.array(x_trn_pad)\n",
    "y_trn = np.array(y_trn_ohv)\n",
    "print(x_trn.shape)\n",
    "print(y_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preparing Test Set\n",
    "- test set is created the same way; except with handling of:\n",
    "    - UNKNOWN words\n",
    "    - MISSING labels (just for safety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# replace words not in training with <UNK>\n",
    "x_tst_int = [[word2idx.get(w, word2idx.get('<UNK>')) for w, t in s] for s in tst]\n",
    "x_tst_pad = pad_sequences(maxlen=max_len, sequences=x_tst_int, padding=\"post\", value=word2idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# replace tags not in training with 'O'\n",
    "y_tst_int = [[label2idx.get(t, label2idx.get('O')) for w, t in s] for s in tst]\n",
    "y_tst_pad = pad_sequences(maxlen=max_len, sequences=y_tst_int, padding=\"post\", value=label2idx['O'])\n",
    "y_tst_ohv = [to_categorical(i, num_classes=len(labels)) for i in y_tst_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# converging to numpy arrays\n",
    "x_tst = np.array(x_tst_pad)\n",
    "y_tst = np.array(y_tst_ohv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1084, 25)\n",
      "(1084, 25, 41)\n"
     ]
    }
   ],
   "source": [
    "print(x_tst.shape)\n",
    "print(y_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Model consists of a set of layers that transform input and predict output.\n",
    "\n",
    "`keras` provides many built-in [layers](https://keras.io/api/layers/).\n",
    "\n",
    "Below are the lists of the important __Core__ and __Recurrent__ layers for us.\n",
    "The layers are briefly described with a few important arguments. \n",
    "\n",
    "Please consult the documentation for full descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Core Layers](https://keras.io/api/layers/core_layers/)\n",
    "\n",
    "- [`Input()`](https://keras.io/api/layers/core_layers/input/) is used to instantiate a Keras tensor. \n",
    "    - `shape=(N,)` argument indicates that the expected input will be batches of N-dimensional vectors. \n",
    "    \n",
    "- [`Embedding()`](https://keras.io/api/layers/core_layers/embedding/) layer can only be used as the first layer in a model. Turns positive integers (indexes) into dense vectors of fixed size. (Embedding layer for word embeddings.)\n",
    "    - `input_dim`: Size of the vocabulary\n",
    "    - `output_dim`: Dimension of the dense embedding.\n",
    "    - `input_length`: Length of input sequences, when it is constant. Required for `Dense` layers upstream.\n",
    "\n",
    "- [`Dense()`](https://keras.io/api/layers/core_layers/dense/) is regular densely-connected NN layer that computes `output = activation(dot(input, kernel) + bias)`\n",
    "    - `units`: dimensionality of the output space.\n",
    "    - `activation`: Activation function to use. (default: \"linear\" activation: a(x) = x).\n",
    "    \n",
    "- [`Activation()`](https://keras.io/api/layers/core_layers/activation/) layer that applies an activation function to an output.\n",
    "    - `activation`: Activation function (e.g. tf.nn.relu), or string name of __built-in__ activation function (e.g. \"relu\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Recurrent Layers](https://keras.io/api/layers/recurrent_layers/)\n",
    "\n",
    "[Guide on working with RNN](https://keras.io/guides/working_with_rnns/).\n",
    "\n",
    "- [`SimpleRNN()`](https://keras.io/api/layers/recurrent_layers/simple_rnn/) is a fully-connected RNN where the output is to be fed back to input.\n",
    "    - `units`: dimensionality of the output space.\n",
    "    - `activation`: activation function to use. Default: hyperbolic tangent (`tanh`). \n",
    "    - `dropout`: Fraction of the units to drop for the linear transformation of the inputs. \n",
    "    - `recurrent_dropout`: Fraction of the units to drop for the linear transformation of the recurrent state. \n",
    "    - `return_sequences`: Boolean. __Whether to return the last output in the output sequence, or the full sequence__. Default: False.\n",
    "\n",
    "- [`LSTM()`](https://keras.io/api/layers/recurrent_layers/lstm/) Long Short-Term Memory\n",
    "    - same and `SimpleRNN` + \n",
    "    - `recurrent_activation`: Activation function to use for the recurrent step. Default: sigmoid (`sigmoid`)\n",
    "    \n",
    "- [`GRU()`](https://keras.io/api/layers/recurrent_layers/gru/) Gated Recurrent Unit \n",
    "    - same and `LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Wrapper Layers for RNN\n",
    "\n",
    "- [`Bidirectional()`](https://keras.io/api/layers/recurrent_layers/bidirectional/) makes RNN bidirectional\n",
    "    - `layer`: keras.layers.RNN instance, such as keras.layers.LSTM or keras.layers.GRU. \n",
    "    - `merge_mode`: Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list. Default value is 'concat'.\n",
    "    - `backward_layer`: Optional. Same as `layer` automatically. \n",
    "\n",
    "- [`TimeDistributed()`](https://keras.io/api/layers/recurrent_layers/time_distributed/) allows to apply a layer to every temporal slice of an input. (e.g. `softmax` to output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Loss Functions](https://keras.io/api/losses/)\n",
    "- Probabilisting Cross Entropy Losses compute the crossentropy loss between the labels and predictions\n",
    "    - `binary_crossentropy`: Use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1)\n",
    "    - `categorical_crossentropy`: Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation.\n",
    "    - `sparse_categorical_crossentropy`: Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Optimizers](https://keras.io/api/optimizers/)\n",
    "One of the two required arguments for model compilation. Available optimizers are:\n",
    "- `SGD`: Gradient descent (with momentum) optimizer \n",
    "- `Adam` Optimizer that implements the Adam algorithm. Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "- Others (read documentation):\n",
    "    - RMSprop\n",
    "    - Adadelta\n",
    "    - Adagrad\n",
    "    - Adamax\n",
    "    - Nadam\n",
    "    - Ftrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Metrics](https://keras.io/api/metrics/)\n",
    "A metric is a function that is used to judge the performance of your model.\n",
    "\n",
    "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n",
    "\n",
    "Available accuracy metrics are:\n",
    "- accuracy\n",
    "- binary accuracy\n",
    "- categorical accuracy\n",
    "\n",
    "There are many other metrics that are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bilding Simple RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's build simple RNN for our data.\n",
    "\n",
    "There are several ways to build a model in Keras.\n",
    "\n",
    "- The __Sequential model__, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).\n",
    "\n",
    "- The __Functional API__, which is an easy-to-use, fully-featured API that supports arbitrary model architectures. For most people and most use cases, this is what you should be using. This is the Keras \"industry strength\" model.\n",
    "\n",
    "- __Model subclassing__, where you implement everything from scratch on your own. Use this if you have complex, out-of-the-box research use cases.\n",
    "\n",
    "We are going to use __Functional API__ approach.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Function API Model Building\n",
    "To build a model using the functional API\n",
    "\n",
    "- start by creating an input node: `inputs = Input(shape=(input_vector_size,))`\n",
    "- create a new node in the graph of layers by calling a layer on this inputs object: `model = layers.Dense(...)(inputs)`\n",
    "- create outputs from a layer: `outputs = layers.Dense(10)(model)`\n",
    "- create a model specifying its inputs and outputs in the graph of layers: `model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")`\n",
    "\n",
    "- model can be inspected using `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, TimeDistributed, Dense, SimpleRNN\n",
    "\n",
    "# input layer\n",
    "inputs = Input(shape=(max_len,))\n",
    "\n",
    "# embedding layer; don't forget we added 'UNK' and 'PAD'\n",
    "# mask_zero=True tells the model that sequence is padded and it should ignore it\n",
    "model = Embedding(input_dim=len(words)+2, output_dim=50, input_length=max_len, mask_zero=True)(inputs)\n",
    "\n",
    "# RNN layer\n",
    "model = SimpleRNN(units=100, return_sequences=True)(model)\n",
    "\n",
    "# softmax output layer\n",
    "outputs = TimeDistributed(Dense(len(labels), activation=\"softmax\"))(model)\n",
    "\n",
    "# defining model\n",
    "model = Model(inputs, outputs, name=\"simple_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 25, 50)            86500     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 25, 100)           15100     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 25, 41)            4141      \n",
      "=================================================================\n",
      "Total params: 105,741\n",
      "Trainable params: 105,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# let's inspect the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compiling the Model\n",
    "[Model API](https://keras.io/api/models/model_training_apis/)\n",
    "\n",
    "model is compiled providing optimizer and loss, and metrics list (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 2s 27ms/step - loss: 0.7968 - accuracy: 0.4966 - val_loss: 0.4116 - val_accuracy: 0.7469\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3717 - accuracy: 0.7154 - val_loss: 0.2918 - val_accuracy: 0.7576\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2394 - accuracy: 0.7602 - val_loss: 0.2449 - val_accuracy: 0.7817\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.1792 - accuracy: 0.8208 - val_loss: 0.2287 - val_accuracy: 0.7934\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.1430 - accuracy: 0.8502 - val_loss: 0.2180 - val_accuracy: 0.8020\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.1153 - accuracy: 0.8807 - val_loss: 0.2129 - val_accuracy: 0.8092\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.1035 - accuracy: 0.8996 - val_loss: 0.2035 - val_accuracy: 0.8195\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0837 - accuracy: 0.9218 - val_loss: 0.2145 - val_accuracy: 0.8048\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0741 - accuracy: 0.9299 - val_loss: 0.2137 - val_accuracy: 0.8118\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0612 - accuracy: 0.9418 - val_loss: 0.2059 - val_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "rnn_history = model.fit(x_trn, y_trn, \n",
    "                        batch_size=64, \n",
    "                        epochs=10, \n",
    "                        validation_split=0.2,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__BEST PRACTICE IS TO AVERAGE PERFORMANCES OF SEVERAL RUNS!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate our model\n",
    "scores = model.evaluate(x_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.1205439567565918, 0.8936349749565125]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)  # to get metric names\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Results look great!\n",
    "\n",
    "However, remember that we padded our data; thus, most of it is due to `O`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Getting Predictions\n",
    "- using `model.predict(x_tst)` for performance in large scale inputs\n",
    "- using `model(x_tst)` for small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1615471e-07 1.9970980e-08 7.2076460e-08 ... 5.8605654e-09\n",
      "  2.5333813e-08 9.9939859e-01]\n",
      " [2.8339803e-10 3.9239532e-12 2.5805294e-11 ... 4.2919848e-11\n",
      "  5.9898031e-11 9.9999833e-01]\n",
      " [7.5490725e-06 8.7174648e-08 2.2182816e-07 ... 3.8386869e-08\n",
      "  3.2921129e-08 3.5385638e-06]\n",
      " ...\n",
      " [2.4051236e-02 2.3626415e-02 2.4015347e-02 ... 2.3585007e-02\n",
      "  2.4465526e-02 2.9772669e-02]\n",
      " [2.4051236e-02 2.3626415e-02 2.4015347e-02 ... 2.3585007e-02\n",
      "  2.4465526e-02 2.9772669e-02]\n",
      " [2.4051236e-02 2.3626415e-02 2.4015347e-02 ... 2.3585007e-02\n",
      "  2.4465526e-02 2.9772669e-02]]\n",
      "[40 40 14 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40]\n"
     ]
    }
   ],
   "source": [
    "all_preds = model.predict(x_tst)\n",
    "max_preds = all_preds.argmax(axis=-1)\n",
    "\n",
    "print(all_preds[0])\n",
    "print(max_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 40 14 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40]\n"
     ]
    }
   ],
   "source": [
    "preds = model(x_tst)\n",
    "preds = np.argmax(preds, -1)\n",
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preparing for CoNLL Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Unpadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def unpad(preds, refs):\n",
    "    # todo: doesnt' take care of truncated input\n",
    "    if len(preds) != len(refs):\n",
    "        raise ValueError\n",
    "    hyps = []\n",
    "    for i, sent in enumerate(refs):\n",
    "        if len(sent) < len(preds[i]):\n",
    "            hyps.append(preds[i][:len(sent)])\n",
    "        else:\n",
    "            if len(sent) > len(preds[i]):\n",
    "                raise ValueError(\"truncated input!\")\n",
    "            hyps.append(preds[i])\n",
    "    return hyps\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Minor format changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('_', 'B-movie.name'), ('_', 'O'), ('_', 'B-movie.name')]\n"
     ]
    }
   ],
   "source": [
    "# let's unpad\n",
    "preds = unpad(preds, tst)\n",
    "# to make tuples, so that we can use the conll eval\n",
    "preds_txt = [[('_', idx2label.get(i)) for i in s] for s in preds]\n",
    "\n",
    "print(preds_txt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.707</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.364</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.358</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.588</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.465</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.434</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.505</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.481</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.174</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.507</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.619</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.852</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.569</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.637</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.693</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.language        0.667  0.754  0.707    69\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "person.name           0.364  0.353  0.358    34\n",
       "award.ceremony        1.000  0.000  0.000     7\n",
       "actor.nationality     1.000  0.000  0.000     1\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.genre           1.000  0.417  0.588    36\n",
       "producer.name         0.536  0.411  0.465    73\n",
       "movie.gross_revenue   0.000  0.000  0.000     5\n",
       "movie.location        1.000  0.000  0.000     7\n",
       "movie.release_region  0.000  0.000  0.000     4\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "actor.type            1.000  0.000  0.000     2\n",
       "director.name         0.434  0.605  0.505    81\n",
       "character.name        1.000  0.000  0.000    15\n",
       "country.name          0.565  0.419  0.481    62\n",
       "movie.release_date    0.150  0.207  0.174    29\n",
       "movie.star_rating     0.000  0.000  0.000     1\n",
       "movie.subject         0.507  0.795  0.619    44\n",
       "rating.name           0.907  0.803  0.852    61\n",
       "actor.name            0.569  0.725  0.637    80\n",
       "movie.name            0.620  0.786  0.693   473\n",
       "total                 0.580  0.645  0.611  1091"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = evaluate(tst, preds_txt)\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Improvements\n",
    "Let's:\n",
    "- Add dropout\n",
    "- Make model bidirectional\n",
    "- Change cell type to LSTM\n",
    "- Explicitly define optimization & set learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "inputs = Input(shape=(max_len,))\n",
    "# don't forget we added 'UNK' and 'PAD'\n",
    "model = Embedding(input_dim=len(words)+2, output_dim=50, input_length=max_len, mask_zero=True)(inputs)\n",
    "# adding dropout\n",
    "model = Dropout(0.5)(model)\n",
    "# making bidirectional LSTM & adding recurrent dropout\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "outputs = TimeDistributed(Dense(len(labels), activation=\"softmax\"))(model)  # softmax output layer\n",
    "\n",
    "model = Model(inputs, outputs, name=\"BiLSTM\")\n",
    "\n",
    "# setting learning rate & decay parameters (read documentation!) \n",
    "opt = Adam(lr=0.01, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 25, 50)            86500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 25, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 25, 41)            8241      \n",
      "=================================================================\n",
      "Total params: 215,541\n",
      "Trainable params: 215,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 6s 72ms/step - loss: 0.5004 - accuracy: 0.6422 - val_loss: 0.2767 - val_accuracy: 0.7504\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.1879 - accuracy: 0.8024 - val_loss: 0.2051 - val_accuracy: 0.8025\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0991 - accuracy: 0.8818 - val_loss: 0.1949 - val_accuracy: 0.8212\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0579 - accuracy: 0.9316 - val_loss: 0.1931 - val_accuracy: 0.8296\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0355 - accuracy: 0.9634 - val_loss: 0.1905 - val_accuracy: 0.8345\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 3s 61ms/step - loss: 0.0296 - accuracy: 0.9685 - val_loss: 0.1955 - val_accuracy: 0.8347\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0220 - accuracy: 0.9743 - val_loss: 0.2017 - val_accuracy: 0.8408\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0134 - accuracy: 0.9856 - val_loss: 0.1830 - val_accuracy: 0.8524\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0142 - accuracy: 0.9847 - val_loss: 0.2024 - val_accuracy: 0.8461\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 3s 60ms/step - loss: 0.0112 - accuracy: 0.9860 - val_loss: 0.2027 - val_accuracy: 0.8508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_trn, y_trn, batch_size=64, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.687</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.657</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.765</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.701</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.400</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.696</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.364</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.516</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.317</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.435</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.763</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.823</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.749</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.858</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.language        0.726  0.652  0.687    69\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "person.name           0.667  0.647  0.657    34\n",
       "award.ceremony        1.000  0.000  0.000     7\n",
       "actor.nationality     1.000  1.000  1.000     1\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.genre           0.689  0.861  0.765    36\n",
       "producer.name         0.770  0.644  0.701    73\n",
       "movie.gross_revenue   0.333  0.200  0.250     5\n",
       "movie.location        0.667  0.286  0.400     7\n",
       "movie.release_region  1.000  0.000  0.000     4\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "actor.type            1.000  1.000  1.000     2\n",
       "director.name         0.714  0.679  0.696    81\n",
       "character.name        0.571  0.267  0.364    15\n",
       "country.name          0.500  0.532  0.516    62\n",
       "movie.release_date    0.317  0.690  0.435    29\n",
       "movie.star_rating     1.000  0.000  0.000     1\n",
       "movie.subject         0.698  0.841  0.763    44\n",
       "rating.name           0.725  0.951  0.823    61\n",
       "actor.name            0.703  0.800  0.749    80\n",
       "movie.name            0.834  0.884  0.858   473\n",
       "total                 0.732  0.770  0.750  1091"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(x_tst)\n",
    "preds = np.argmax(preds, -1)\n",
    "preds = unpad(preds, tst)\n",
    "# to make tuples, so that we can use the conll eval\n",
    "preds = [[('_', idx2label.get(i)) for i in s] for s in preds]\n",
    "results = evaluate(tst, preds)\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read [documentation](https://keras.io/examples/nlp/pretrained_word_embeddings/) on how to use embeddings and all the parameters.\n",
    "\n",
    "Here we are going to do a simple illustration with embeddings of spacy.\n",
    "\n",
    "`python -m spacy download en_core_web_lg` to get proper vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# let's get embedding vector & inspect its properties\n",
    "vec = nlp.vocab['movie'].vector\n",
    "\n",
    "emb_dimension = len(vec)\n",
    "print(emb_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1730\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words) + 2\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1730 words (0 misses)\n"
     ]
    }
   ],
   "source": [
    "# let's initialize embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab_size, emb_dimension))\n",
    "hits = 0\n",
    "misses = 0\n",
    "for word, i in word2idx.items():\n",
    "    embedding_vector = nlp.vocab[word].vector\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model with Pre-Trained Embeddings\n",
    "copy from above (some parameter changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from keras.optimizers import Adam\n",
    "# new one\n",
    "from keras.initializers import Constant\n",
    "\n",
    "inputs = Input(shape=(max_len,))\n",
    "# note new parameters\n",
    "model = Embedding(input_dim=vocab_size, \n",
    "                  output_dim=emb_dimension, \n",
    "                  embeddings_initializer=Constant(embedding_matrix), \n",
    "                  trainable=False,  # to keep embeddings frozen\n",
    "                  mask_zero=True,\n",
    "                  input_length=max_len)(inputs)\n",
    "# adding dropout\n",
    "model = Dropout(0.5)(model)\n",
    "# making bidirectional LSTM & adding recurrent dropout\n",
    "model = Bidirectional(LSTM(units=emb_dimension, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "outputs = TimeDistributed(Dense(len(labels), activation=\"softmax\"))(model)  # softmax output layer\n",
    "\n",
    "model = Model(inputs, outputs, name=\"BiLSTM.emb\")\n",
    "\n",
    "# setting learning rate & decay parameters (read documentation!) \n",
    "opt = Adam(lr=0.01, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM.emb\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 25, 300)           519000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 25, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 25, 41)            24641     \n",
      "=================================================================\n",
      "Total params: 1,986,041\n",
      "Trainable params: 1,467,041\n",
      "Non-trainable params: 519,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 19s 362ms/step - loss: 0.2616 - accuracy: 0.7393 - val_loss: 0.1601 - val_accuracy: 0.8410\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 0.0545 - accuracy: 0.9364 - val_loss: 0.1377 - val_accuracy: 0.8657\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 0.0281 - accuracy: 0.9686 - val_loss: 0.1341 - val_accuracy: 0.8795\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 14s 340ms/step - loss: 0.0183 - accuracy: 0.9777 - val_loss: 0.1503 - val_accuracy: 0.8744\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 14s 343ms/step - loss: 0.0118 - accuracy: 0.9873 - val_loss: 0.1521 - val_accuracy: 0.8742\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 14s 339ms/step - loss: 0.0089 - accuracy: 0.9891 - val_loss: 0.1439 - val_accuracy: 0.8942\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 0.0069 - accuracy: 0.9911 - val_loss: 0.1521 - val_accuracy: 0.8786\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 14s 345ms/step - loss: 0.0050 - accuracy: 0.9941 - val_loss: 0.1624 - val_accuracy: 0.8835\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 0.0048 - accuracy: 0.9945 - val_loss: 0.1628 - val_accuracy: 0.8854\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 15s 355ms/step - loss: 0.0046 - accuracy: 0.9942 - val_loss: 0.1698 - val_accuracy: 0.8842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_trn, y_trn, batch_size=64, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 67ms/step - loss: 0.0866 - accuracy: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08656857907772064, 0.9409863948822021]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.672</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.708</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.758</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.838</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.154</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.400</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.780</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.545</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.576</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.667</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.588</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.742</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.894</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.824</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.854</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.789</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.language        0.800  0.580  0.672    69\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "person.name           0.742  0.676  0.708    34\n",
       "award.ceremony        1.000  0.000  0.000     7\n",
       "actor.nationality     0.500  1.000  0.667     1\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.genre           0.833  0.694  0.758    36\n",
       "producer.name         0.905  0.781  0.838    73\n",
       "movie.gross_revenue   0.125  0.200  0.154     5\n",
       "movie.location        0.667  0.286  0.400     7\n",
       "movie.release_region  1.000  0.000  0.000     4\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "actor.type            1.000  1.000  1.000     2\n",
       "director.name         0.795  0.765  0.780    81\n",
       "character.name        0.857  0.400  0.545    15\n",
       "country.name          0.576  0.790  0.667    62\n",
       "movie.release_date    0.513  0.690  0.588    29\n",
       "movie.star_rating     1.000  0.000  0.000     1\n",
       "movie.subject         0.679  0.818  0.742    44\n",
       "rating.name           0.887  0.902  0.894    61\n",
       "actor.name            0.778  0.875  0.824    80\n",
       "movie.name            0.819  0.892  0.854   473\n",
       "total                 0.779  0.798  0.789  1091"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(x_tst)\n",
    "preds = np.argmax(preds, -1)\n",
    "preds = unpad(preds, tst)\n",
    "# to make tuples, so that we can use the conll eval\n",
    "preds = [[('_', idx2label.get(i)) for i in s] for s in preds]\n",
    "results = evaluate(tst, preds)\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n",
    "- Experiment with different model parameters\n",
    "    - vary hidden layer size\n",
    "    - learning rate\n",
    "    - dropout rate\n",
    "    - batch size\n",
    "    - cell type: LSTM, GRU, SimpleRNN\n",
    "    - optimizer: SGD, Adam, others\n",
    "    \n",
    "- We have used post-padding, the default is pre-padding.\n",
    "    - change the padding & unpadding\n",
    "    - train & evaluate one of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
